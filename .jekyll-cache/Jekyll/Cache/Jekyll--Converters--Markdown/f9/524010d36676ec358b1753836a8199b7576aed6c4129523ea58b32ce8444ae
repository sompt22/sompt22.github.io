I"³<p>SOMPT22 is a Multi-Object Tracking Dataset</p>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/tumbnail.png" alt="" width="1920" height="1000" />
  
</figure>

<p><a class="button" href="https://github.com/sompt" style="background: #0366d6">Fork itÂ  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a>
 <a class="button" href="https://twitter.com/" style="background: #0d94e7">Tweet itÂ  <svg width="16" height="16" class="icon  icon--twitter" role="img" alt="twitter"><title>twitter</title><use xlink:href="#twitter" fill="CurrentColor"></use></svg>
</a>
 <a class="button" href="https://arxiv.org/abs/2208.02580" style="background: #0d94e7">PaperÂ  <svg width="16" height="16" class="icon  icon--link" role="img" alt="link"><title>link</title><use xlink:href="#link" fill="CurrentColor"></use></svg>
</a></p>

<h2 id="abstract">Abstract</h2>

<p>Multi-object tracking (MOT) has been dominated by the use of track by detection approaches due to the success of convolutional neural networks (CNNs) on detection in the last decade. As the datasets and bench-marking sites are published, research direction has shifted towards yielding best accuracy on generic scenarios including re-identification
(reID) of objects while tracking. In this study, we narrow the scope of MOT for surveillance by providing a dedicated dataset of pedestrians and focus on in-depth analyses of well performing multi-object trackers to observe the weak and strong sides of state-of-the-art (SOTA) techniques for real-world applications. For this purpose, we introduce SOMPT22 dataset; a new set for multi person tracking with annotated short videos
captured from static cameras located on poles with 6-8 meters in height positioned for city surveillance. This provides a more focused and specific benchmarking of MOT for outdoor surveillance compared to public MOT datasets. We analyze MOT trackers classified as one-shot and two-stage with respect to the way of use of detection and reID networks on
this new dataset. The experimental results of our new dataset indicate that SOTA is still far from high efficiency, and single-shot trackers are good candidates to unify fast execution and accuracy with competitive performance.</p>

<h2 id="detection--tracking-datasets">Detection &amp; Tracking Datasets</h2>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/table1_1.png" alt="" width="1920" height="1000" />
  
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/table2_2.png" alt="" width="1920" height="1000" />
  
</figure>

<h2 id="sompt22-statistics">SOMPT22 Statistics</h2>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/fig1_3.png" alt="" width="1920" height="1000" />
  
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/table3_4.png" alt="" width="1920" height="1000" />
  
</figure>

<h2 id="experiment-setup">Experiment Setup</h2>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/table4-5.png" alt="" width="1920" height="1000" />
  
</figure>

<h2 id="benchmark-results">Benchmark Results</h2>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/table6-7.png" alt="" width="1920" height="1000" />
  
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/table8.png" alt="" width="1920" height="1000" />
  
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/table9.png" alt="" width="1920" height="1000" />
  
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/assets/paper_pics/fig2.png" alt="" width="1920" height="1000" />
  
</figure>

<h2 id="citation">Citation</h2>

<div class="language-css highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">@misc</span><span class="p">{</span><span class="py">https</span><span class="p">://</span><span class="n">doi</span><span class="p">.</span><span class="n">org</span><span class="p">/</span><span class="m">10.48550</span><span class="p">/</span><span class="n">arxiv</span><span class="m">.2208.02580</span><span class="p">,</span>
  <span class="n">doi</span> <span class="err">=</span> <span class="err">{</span><span class="m">10.48550</span><span class="p">/</span><span class="n">ARXIV</span><span class="m">.2208.02580</span><span class="p">}</span><span class="o">,</span>
  <span class="nt">url</span> <span class="o">=</span> <span class="p">{</span><span class="py">https</span><span class="p">://</span><span class="n">arxiv</span><span class="p">.</span><span class="n">org</span><span class="p">/</span><span class="n">abs</span><span class="p">/</span><span class="m">2208.02580</span><span class="p">}</span><span class="o">,</span>
  <span class="nt">author</span> <span class="o">=</span> <span class="p">{</span><span class="err">Simsek,</span> <span class="err">Fatih</span> <span class="err">Emre</span> <span class="err">and</span> <span class="err">Cigla,</span> <span class="err">Cevahir</span> <span class="err">and</span> <span class="err">Kayabol,</span> <span class="err">Koray</span><span class="p">}</span><span class="o">,</span>
  <span class="nt">keywords</span> <span class="o">=</span> <span class="p">{</span><span class="err">Computer</span> <span class="err">Vision</span> <span class="err">and</span> <span class="err">Pattern</span> <span class="err">Recognition</span> <span class="err">(cs.CV),</span> <span class="py">FOS</span><span class="p">:</span> <span class="n">Computer</span> <span class="n">and</span> <span class="n">information</span> <span class="n">sciences</span><span class="p">,</span> <span class="n">FOS</span><span class="p">:</span> <span class="n">Computer</span> <span class="n">and</span> <span class="n">information</span> <span class="n">sciences</span><span class="p">}</span><span class="o">,</span>
  <span class="nt">title</span> <span class="o">=</span> <span class="p">{</span><span class="py">SOMPT22</span><span class="p">:</span> <span class="n">A</span> <span class="n">Surveillance</span> <span class="n">Oriented</span> <span class="n">Multi-Pedestrian</span> <span class="n">Tracking</span> <span class="n">Dataset</span><span class="p">}</span><span class="o">,</span>
  <span class="nt">publisher</span> <span class="o">=</span> <span class="p">{</span><span class="err">arXiv</span><span class="p">}</span><span class="o">,</span>
  <span class="nt">year</span> <span class="o">=</span> <span class="p">{</span><span class="err">2022</span><span class="p">}</span><span class="o">,</span>
  <span class="nt">copyright</span> <span class="o">=</span> <span class="p">{</span><span class="err">Creative</span> <span class="err">Commons</span> <span class="err">Attribution</span> <span class="err">Non</span> <span class="err">Commercial</span> <span class="err">Share</span> <span class="err">Alike</span> <span class="err">4.0</span> <span class="err">International</span><span class="p">}</span>
<span class="err">}</span>
</code></pre></div></div>

<h2 id="license">License</h2>
:ET